{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas_ta as ta  # Technical indicators\n",
    "from tqdm import tqdm   # Progress bars\n",
    "\n",
    "# Configuration\n",
    "RAW_DIR = \"../data/raw/yfinance\"\n",
    "PROCESSED_DIR = \"../data/processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk Load All YFinance Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 438.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 25000 rows from 100 stocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_2416\\1239331118.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(all_dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def load_all_yfinance():\n",
    "    \"\"\"Load Yahoo Finance CSVs with multi-row headers\"\"\"\n",
    "    all_dfs = []\n",
    "    \n",
    "    for file in tqdm(os.listdir(RAW_DIR)):\n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                ticker = file.split('.')[0]\n",
    "                \n",
    "                # Skip the first 3 rows of metadata\n",
    "                df = pd.read_csv(\n",
    "                    f\"{RAW_DIR}/{file}\",\n",
    "                    skiprows=3,\n",
    "                    names=['date', 'close', 'high', 'low', 'open', 'volume'],\n",
    "                    parse_dates=['date']\n",
    "                )\n",
    "                \n",
    "                df['ticker'] = ticker\n",
    "                all_dfs.append(df)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed {file}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "df = load_all_yfinance()\n",
    "print(f\"✅ Loaded {len(df)} rows from {df['ticker'].nunique()} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date       close        high         low        open     volume ticker\n",
      "0 2024-04-01  169.230927  170.445194  168.683508  170.385479   46240500   AAPL\n",
      "1 2024-04-02  168.046494  168.544144  167.439360  168.285371   49329500   AAPL\n",
      "2 2024-04-03  168.852692  169.877850  167.787728  167.996733   47691700   AAPL\n",
      "3 2024-04-04  168.026611  171.112033  168.026611  169.489689   53704400   AAPL\n",
      "4 2024-04-05  168.783051  169.589241  168.156006  168.792998   42055200   AAPL\n",
      "5 2024-04-08  167.658356  168.404831  167.449351  168.235632   37425500   AAPL\n",
      "6 2024-04-09  168.872620  169.280696  167.558831  167.907177   42451200   AAPL\n",
      "7 2024-04-10  166.991486  168.295327  166.324636  168.006696   49709300   AAPL\n",
      "8 2024-04-11  174.217361  174.635401  167.369706  167.548852   91070300   AAPL\n",
      "9 2024-04-12  175.720276  177.521767  173.391277  173.441030  101593300   AAPL\n",
      "Tickers: ['AAPL', 'ABNB', 'ADBE', 'ADI', 'ADP']...\n"
     ]
    }
   ],
   "source": [
    "print(df[df['ticker'] == 'AAPL'].head(10))\n",
    "unique_tickers = df['ticker'].unique().tolist()\n",
    "print(f\"Tickers: {unique_tickers[:5]}...\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning Pipeline\n",
    "Goal: Fix common data quality issues\n",
    "\n",
    "Why?\n",
    "Ensures dates are recognized as timestamps (not strings)\n",
    ", Handles market closures without leaving gaps\n",
    ", Guarantees no NaN values break your models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Convert text dates to proper datetime format (essential for time series)\n",
    "    df['date'] = pd.to_datetime(df['date'])  \n",
    "    \n",
    "    # Forward-fill missing values (e.g., weekends/holidays when markets are closed)\n",
    "    df = df.sort_values(['ticker', 'date'])\n",
    "    df = df.groupby('ticker').apply(lambda x: x.ffill())  # Carry last known value forward\n",
    "    \n",
    "    # Remove any remaining bad rows\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n",
      "\n",
      "NaN per column:\n",
      "date      0\n",
      "close     0\n",
      "high      0\n",
      "low       0\n",
      "open      0\n",
      "volume    0\n",
      "ticker    0\n",
      "dtype: int64\n",
      "(25000, 7)\n",
      "        date       close        high         low        open     volume ticker\n",
      "0 2024-04-01  169.230927  170.445194  168.683508  170.385479   46240500   AAPL\n",
      "1 2024-04-02  168.046494  168.544144  167.439360  168.285371   49329500   AAPL\n",
      "2 2024-04-03  168.852692  169.877850  167.787728  167.996733   47691700   AAPL\n",
      "3 2024-04-04  168.026611  171.112033  168.026611  169.489689   53704400   AAPL\n",
      "4 2024-04-05  168.783051  169.589241  168.156006  168.792998   42055200   AAPL\n",
      "5 2024-04-08  167.658356  168.404831  167.449351  168.235632   37425500   AAPL\n",
      "6 2024-04-09  168.872620  169.280696  167.558831  167.907177   42451200   AAPL\n",
      "7 2024-04-10  166.991486  168.295327  166.324636  168.006696   49709300   AAPL\n",
      "8 2024-04-11  174.217361  174.635401  167.369706  167.548852   91070300   AAPL\n",
      "9 2024-04-12  175.720276  177.521767  173.391277  173.441030  101593300   AAPL\n"
     ]
    }
   ],
   "source": [
    "# Total NaN values in entire DataFrame\n",
    "total_nans = df.isna().sum().sum()\n",
    "print(f\"Total NaN values: {total_nans}\")\n",
    "\n",
    "# NaN count per column\n",
    "nan_per_column = df.isna().sum()\n",
    "print(\"\\nNaN per column:\")\n",
    "print(nan_per_column)\n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "Goal: Add technical indicators traders use\n",
    "\n",
    "Why These Indicators?\n",
    "\n",
    "SMA: Smooths price noise to reveal trends\n",
    "\n",
    "RSI: Identifies potential reversals (values >70 = overbought, <30 = oversold)\n",
    "\n",
    "MACD: Shows momentum shifts\n",
    "\n",
    "Bollinger Bands: Highlights volatility extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    # Calculate indicators PER STOCK (groupby ensures no cross-contamination)\n",
    "    return df.groupby('ticker').apply(lambda x: x.assign(\n",
    "        sma_20=ta.sma(x['close'], 20),       # 20-day moving average (trend direction)\n",
    "        rsi_14=ta.rsi(x['close'], 14),       # Relative Strength Index (overbought/oversold)\n",
    "        macd=ta.macd(x['close'])['MACD_12_26_9'],  # MACD (momentum)\n",
    "        boll_high=ta.bbands(x['close'])['BBU_5_2.0'],  # Bollinger Upper Band (volatility)\n",
    "        boll_low=ta.bbands(x['close'])['BBL_5_2.0']    # Bollinger Lower Band\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns: ['date', 'close', 'high', 'low', 'open', 'volume', 'ticker', 'sma_20', 'rsi_14', 'macd', 'boll_high', 'boll_low']\n",
      "\n",
      "AAPL data with indicators:\n",
      "                 date       close        high         low        open  \\\n",
      "ticker                                                                  \n",
      "AAPL   247 2025-03-26  221.529999  225.020004  220.470001  223.509995   \n",
      "       248 2025-03-27  223.850006  224.990005  220.559998  221.389999   \n",
      "       249 2025-03-28  217.899994  223.809998  217.679993  221.669998   \n",
      "\n",
      "              volume ticker    sma_20     rsi_14      macd   boll_high  \\\n",
      "ticker                                                                   \n",
      "AAPL   247  34532700   AAPL  224.6010  44.768952 -4.701965  226.261696   \n",
      "       248  37094800   AAPL  223.9285  47.775590 -4.108380  225.776406   \n",
      "       249  39784100   AAPL  222.7315  41.531256 -4.071146  225.945208   \n",
      "\n",
      "              boll_low  \n",
      "ticker                  \n",
      "AAPL   247  213.090306  \n",
      "       248  217.475596  \n",
      "       249  217.158790  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_2416\\4279645356.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby('ticker').apply(lambda x: x.assign(\n"
     ]
    }
   ],
   "source": [
    "df_features = add_technical_indicators(df)\n",
    "# Check new columns\n",
    "print(\"New columns:\", df_features.columns.tolist())\n",
    "# See sample data for AAPL\n",
    "print(\"\\nAAPL data with indicators:\")\n",
    "print(df_features[df_features['ticker'] == 'AAPL'].tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs: 0\n",
      "                date       close        high         low        open  \\\n",
      "ticker                                                                 \n",
      "AAPL   25 2024-05-06  180.856033  183.334321  179.572087  181.493025   \n",
      "       26 2024-05-07  181.542770  184.031021  180.467859  182.587839   \n",
      "       27 2024-05-08  181.881195  182.209646  180.597249  181.990679   \n",
      "       28 2024-05-09  183.702591  183.792164  181.254145  181.702028   \n",
      "       29 2024-05-10  182.436859  184.470019  181.519943  184.280653   \n",
      "\n",
      "             volume ticker      sma_20     rsi_14      macd   boll_high  \\\n",
      "ticker                                                                    \n",
      "AAPL   25  78569700   AAPL  170.363071  66.934952  2.860254  186.397304   \n",
      "       26  77305800   AAPL  170.996579  67.682981  3.347573  188.474161   \n",
      "       27  45057100   AAPL  171.741064  68.066382  3.718223  187.464700   \n",
      "       28  48983000   AAPL  172.215326  70.120928  4.111543  184.028681   \n",
      "       29  50759500   AAPL  172.551155  66.899753  4.271874  183.999365   \n",
      "\n",
      "             boll_low  \n",
      "ticker                 \n",
      "AAPL   25  163.052653  \n",
      "       26  165.781100  \n",
      "       27  172.141299  \n",
      "       28  180.171630  \n",
      "       29  180.168414  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_2416\\1399340213.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_features = df_features.ffill()\n"
     ]
    }
   ],
   "source": [
    "# Forward-fill missing values (carry last known value forward)\n",
    "df_features = df_features.ffill()\n",
    "\n",
    "# OR drop early rows with NaN\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "print(\"Remaining NaNs:\", df_features.isna().sum().sum())  # Should be 0\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max gap between dates per ticker (should be <=3 days for weekends):\n",
      "date\n",
      "4    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if any ticker has date gaps\n",
    "date_gaps = df.groupby('ticker')['date'].apply(lambda x: x.sort_values().diff().max())\n",
    "print(\"Max gap between dates per ticker (should be <=3 days for weekends):\")\n",
    "print(date_gaps.dt.days.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
